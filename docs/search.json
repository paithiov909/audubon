[{"path":"https://paithiov909.github.io/audubon/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Akiru Kato. Maintainer.","code":""},{"path":"https://paithiov909.github.io/audubon/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kato (2022). audubon: R Package Various Japanese Text Processing. R package version 0.0.5.","code":"@Manual{,   title = {audubon: R Package for Various Japanese Text Processing},   author = {Akiru Kato},   year = {2022},   note = {R package version 0.0.5}, }"},{"path":"https://paithiov909.github.io/audubon/index.html","id":"audubon-","dir":"","previous_headings":"","what":"R Package for Various Japanese Text Processing","title":"R Package for Various Japanese Text Processing","text":"audubon R package various Japanese text processing contains: wrapper functions hakatashi/japanese.js google/budoux R port SudachiCharNormalizer miscellaneous functions","code":""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R Package for Various Japanese Text Processing","text":"","code":"remotes::install_github(\"paithio909/audubon\")"},{"path":[]},{"path":"https://paithiov909.github.io/audubon/index.html","id":"fill-japanese-iteration-marks-踊り字","dir":"","previous_headings":"Usage","what":"Fill Japanese iteration marks (踊り字)","title":"R Package for Various Japanese Text Processing","text":"","code":"## 5文字以上あるとき直前の文字を繰り返して踊り字を置換する strj_fill_iter_mark(c(\"あいうゝ〃かき\",                       \"金子みすゞ\", ## 濁点付きの場合には半角の濁点を付ける                       \"のたり〳〵かな\", ## 2倍の踊り字（くの字点）まで対応している                       \"しろ／″＼とした\")) ## 青空文庫の記法も #> [1] \"あいううゝかき\"             \"金子みすすﾞ\"                #> [3] \"のたり<U+3033><U+3035>かな\" \"しろしﾞろとした\" ## 文字正規化とあわせて使う想定 strj_fill_iter_mark(\"いすゞエルフトラック\") %>%   strj_normalize() #> [1] \"いすずエルフトラック\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"character-class-conversion","dir":"","previous_headings":"Usage","what":"Character class conversion","title":"R Package for Various Japanese Text Processing","text":"","code":"strj_hiraganize(\"あのイーハトーヴォのすきとおった風\") #> [1] \"あのいーはとーヴぉのすきとおった風\" strj_katakanize(\"あのイーハトーヴォのすきとおった風\") #> [1] \"アノイーハトーヴォノスキトオッタ風\" strj_romanize(\"あのイーハトーヴォのすきとおった風\") #> [1] \"ano<U+012B>hat<U+014D>vonosukit<U+014D>tta\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"japanese-text-normalization-1","dir":"","previous_headings":"Usage","what":"Japanese text normalization (1)","title":"R Package for Various Japanese Text Processing","text":"","code":"## Neologd（https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja）の文字正規化 strj_normalize(\"――南アルプスの　天然水-　Ｓｐａｒｋｉｎｇ*　Ｌｅｍｏｎ+　レモン一絞り\") #> [1] \"ー南アルプスの天然水-Sparking* Lemon+レモン一絞り\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"japanese-text-normalization-2","dir":"","previous_headings":"Usage","what":"Japanese text normalization (2)","title":"R Package for Various Japanese Text Processing","text":"","code":"## ふつうのNFKC正規化 stringi::stri_trans_nfkc(\"Ⅹⅳ\") #> [1] \"Xiv\" ## Sudachiの文字正規化（rewrite.defによる文字置換＋NFKC正規化の部分）を移植したもの ## Sudachiのrewrite.defではローマ数字などはNFKC正規化されない strj_rewrite_as_def(\"Ⅹⅳ\") #> [1] \"Ⅹⅳ\" ## tolowerはしない strj_rewrite_as_def(\"謎のヒロインX\") #> [1] \"謎のヒロインX\" ## 旧字を新字体に寄せる strj_rewrite_as_def(\"惡と假面のルール\", read_rewrite_def(system.file(\"def/kyuji.def\", package = \"audubon\"))) #> [1] \"悪と仮面のルール\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"R Package for Various Japanese Text Processing","text":"MIT license. Icons made iconixar www.flaticon.com.","code":""},{"path":"https://paithiov909.github.io/audubon/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 audubon authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/audubon-package.html","id":null,"dir":"Reference","previous_headings":"","what":"audubon:  R Package for Various Japanese Text Processing — audubon-package","title":"audubon:  R Package for Various Japanese Text Processing — audubon-package","text":"R package various Japanese text processing.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/audubon-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"audubon:  R Package for Various Japanese Text Processing — audubon-package","text":"Maintainer: Akiru Kato paithiov909@gmail.com","code":""},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Ngrams tokenizer — ngram_tokenizer","title":"Ngrams tokenizer — ngram_tokenizer","text":"Make ngram tokenizer function.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ngrams tokenizer — ngram_tokenizer","text":"","code":"ngram_tokenizer(n = 1L, skip_word_none = FALSE, locale = NULL)"},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ngrams tokenizer — ngram_tokenizer","text":"n Integer. skip_word_none Logical. locale Character scalar. Pass NULL empty string default locale.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ngrams tokenizer — ngram_tokenizer","text":"ngram tokenizer function","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":null,"dir":"Reference","previous_headings":"","what":"Pack prettified data.frame of tokens — pack","title":"Pack prettified data.frame of tokens — pack","text":"Pack prettified data.frame tokens new data.frame corpus, compatible Text Interchange Formats.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pack prettified data.frame of tokens — pack","text":"","code":"pack(df, n = 1L, pull = \"token\", sep = \"-\", .collapse = \" \")"},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pack prettified data.frame of tokens — pack","text":"df prettified data.frame tokens. n Integer internally passed ngrams tokenizer function created audubon::ngram_tokenizer() pull Column packed text ngrams body. Default value token. sep Character scalar internally used concatenator ngrams. .collapse argument passed stringi::stri_join().","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pack prettified data.frame of tokens — pack","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"text-interchange-formats-tif-","dir":"Reference","previous_headings":"","what":"Text Interchange Formats (TIF)","title":"Pack prettified data.frame of tokens — pack","text":"Text Interchange Formats (TIF) set standards allows R text analysis packages target defined inputs outputs corpora, tokens, document-term matrices.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"valid-data-frame-of-tokens","dir":"Reference","previous_headings":"","what":"Valid data.frame of tokens","title":"Pack prettified data.frame of tokens — pack","text":"prettified data.frame tokens data.frame object compatible TIF. TIF valid data.frame tokens expected one unique key column (named doc_id) text several feature columns tokens. feature columns must contain least token .","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://paithiov909.github.io/audubon/reference/polano.html","id":null,"dir":"Reference","previous_headings":"","what":"Whole text of 'Porano no Hiroba' written by Miyazawa Kenji\r\nfrom Aozora Bunko — polano","title":"Whole text of 'Porano no Hiroba' written by Miyazawa Kenji\r\nfrom Aozora Bunko — polano","text":"Whole text 'Porano Hiroba' written Miyazawa Kenji Aozora Bunko","code":""},{"path":"https://paithiov909.github.io/audubon/reference/polano.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Whole text of 'Porano no Hiroba' written by Miyazawa Kenji\r\nfrom Aozora Bunko — polano","text":"","code":"polano"},{"path":"https://paithiov909.github.io/audubon/reference/polano.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Whole text of 'Porano no Hiroba' written by Miyazawa Kenji\r\nfrom Aozora Bunko — polano","text":"object class character length 899.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/polano.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Whole text of 'Porano no Hiroba' written by Miyazawa Kenji\r\nfrom Aozora Bunko — polano","text":"https://www.aozora.gr.jp/cards/000081/files/1935_ruby_19924.zip","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":null,"dir":"Reference","previous_headings":"","what":"Read rewrite.def file — read_rewrite_def","title":"Read rewrite.def file — read_rewrite_def","text":"Read rewrite.def file","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read rewrite.def file — read_rewrite_def","text":"","code":"read_rewrite_def(   def_path = system.file(\"def/rewrite.def\", package = \"audubon\") )"},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read rewrite.def file — read_rewrite_def","text":"def_path Character scalar; path rewriting definition file.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read rewrite.def file — read_rewrite_def","text":"List.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read rewrite.def file — read_rewrite_def","text":"","code":"str(read_rewrite_def()) #> List of 2 #>  $ ignore :List of 836 #>   ..$ : chr \"Ⅰ\" #>   ..$ : chr \"Ⅱ\" #>   ..$ : chr \"Ⅲ\" #>   ..$ : chr \"Ⅳ\" #>   ..$ : chr \"Ⅴ\" #>   ..$ : chr \"Ⅵ\" #>   ..$ : chr \"Ⅶ\" #>   ..$ : chr \"Ⅷ\" #>   ..$ : chr \"Ⅸ\" #>   ..$ : chr \"Ⅹ\" #>   ..$ : chr \"<U+216A>\" #>   ..$ : chr \"<U+216B>\" #>   ..$ : chr \"<U+216C>\" #>   ..$ : chr \"<U+216D>\" #>   ..$ : chr \"<U+216E>\" #>   ..$ : chr \"<U+216F>\" #>   ..$ : chr \"ⅰ\" #>   ..$ : chr \"ⅱ\" #>   ..$ : chr \"ⅲ\" #>   ..$ : chr \"ⅳ\" #>   ..$ : chr \"ⅴ\" #>   ..$ : chr \"ⅵ\" #>   ..$ : chr \"ⅶ\" #>   ..$ : chr \"ⅷ\" #>   ..$ : chr \"ⅸ\" #>   ..$ : chr \"ⅹ\" #>   ..$ : chr \"<U+217A>\" #>   ..$ : chr \"<U+217B>\" #>   ..$ : chr \"<U+217C>\" #>   ..$ : chr \"<U+217D>\" #>   ..$ : chr \"<U+217E>\" #>   ..$ : chr \"<U+217F>\" #>   ..$ : chr \"<U+2E80>\" #>   ..$ : chr \"<U+2E81>\" #>   ..$ : chr \"<U+2E82>\" #>   ..$ : chr \"<U+2E83>\" #>   ..$ : chr \"<U+2E84>\" #>   ..$ : chr \"<U+2E85>\" #>   ..$ : chr \"<U+2E86>\" #>   ..$ : chr \"<U+2E87>\" #>   ..$ : chr \"<U+2E88>\" #>   ..$ : chr \"<U+2E89>\" #>   ..$ : chr \"<U+2E8A>\" #>   ..$ : chr \"<U+2E8B>\" #>   ..$ : chr \"<U+2E8C>\" #>   ..$ : chr \"<U+2E8D>\" #>   ..$ : chr \"<U+2E8E>\" #>   ..$ : chr \"<U+2E8F>\" #>   ..$ : chr \"<U+2E90>\" #>   ..$ : chr \"<U+2E91>\" #>   ..$ : chr \"<U+2E92>\" #>   ..$ : chr \"<U+2E93>\" #>   ..$ : chr \"<U+2E94>\" #>   ..$ : chr \"<U+2E95>\" #>   ..$ : chr \"<U+2E96>\" #>   ..$ : chr \"<U+2E97>\" #>   ..$ : chr \"<U+2E98>\" #>   ..$ : chr \"<U+2E99>\" #>   ..$ : chr \"<U+2E9B>\" #>   ..$ : chr \"<U+2E9C>\" #>   ..$ : chr \"<U+2E9D>\" #>   ..$ : chr \"<U+2E9E>\" #>   ..$ : chr \"<U+2E9F>\" #>   ..$ : chr \"<U+2EA0>\" #>   ..$ : chr \"<U+2EA1>\" #>   ..$ : chr \"<U+2EA2>\" #>   ..$ : chr \"<U+2EA3>\" #>   ..$ : chr \"<U+2EA4>\" #>   ..$ : chr \"<U+2EA5>\" #>   ..$ : chr \"<U+2EA6>\" #>   ..$ : chr \"<U+2EA7>\" #>   ..$ : chr \"<U+2EA8>\" #>   ..$ : chr \"<U+2EA9>\" #>   ..$ : chr \"<U+2EAA>\" #>   ..$ : chr \"<U+2EAB>\" #>   ..$ : chr \"<U+2EAC>\" #>   ..$ : chr \"<U+2EAD>\" #>   ..$ : chr \"<U+2EAE>\" #>   ..$ : chr \"<U+2EAF>\" #>   ..$ : chr \"<U+2EB0>\" #>   ..$ : chr \"<U+2EB1>\" #>   ..$ : chr \"<U+2EB2>\" #>   ..$ : chr \"<U+2EB3>\" #>   ..$ : chr \"<U+2EB4>\" #>   ..$ : chr \"<U+2EB5>\" #>   ..$ : chr \"<U+2EB6>\" #>   ..$ : chr \"<U+2EB7>\" #>   ..$ : chr \"<U+2EB8>\" #>   ..$ : chr \"<U+2EB9>\" #>   ..$ : chr \"<U+2EBA>\" #>   ..$ : chr \"<U+2EBB>\" #>   ..$ : chr \"<U+2EBC>\" #>   ..$ : chr \"<U+2EBD>\" #>   ..$ : chr \"<U+2EBE>\" #>   ..$ : chr \"<U+2EBF>\" #>   ..$ : chr \"<U+2EC0>\" #>   ..$ : chr \"<U+2EC1>\" #>   ..$ : chr \"<U+2EC2>\" #>   ..$ : chr \"<U+2EC3>\" #>   .. [list output truncated] #>  $ replace:List of 182 #>   ..$ : chr [1:2] \"ｳﾞ\" \"ヴ\" #>   ..$ : chr [1:2] \"ｶﾞ\" \"ガ\" #>   ..$ : chr [1:2] \"ｷﾞ\" \"ギ\" #>   ..$ : chr [1:2] \"ｸﾞ\" \"グ\" #>   ..$ : chr [1:2] \"ｹﾞ\" \"ゲ\" #>   ..$ : chr [1:2] \"ｺﾞ\" \"ゴ\" #>   ..$ : chr [1:2] \"ｻﾞ\" \"ザ\" #>   ..$ : chr [1:2] \"ｼﾞ\" \"ジ\" #>   ..$ : chr [1:2] \"ｽﾞ\" \"ズ\" #>   ..$ : chr [1:2] \"ｾﾞ\" \"ゼ\" #>   ..$ : chr [1:2] \"ｿﾞ\" \"ゾ\" #>   ..$ : chr [1:2] \"ﾀﾞ\" \"ダ\" #>   ..$ : chr [1:2] \"ﾁﾞ\" \"ヂ\" #>   ..$ : chr [1:2] \"ﾂﾞ\" \"ヅ\" #>   ..$ : chr [1:2] \"ﾃﾞ\" \"デ\" #>   ..$ : chr [1:2] \"ﾄﾞ\" \"ド\" #>   ..$ : chr [1:2] \"ﾊﾞ\" \"バ\" #>   ..$ : chr [1:2] \"ﾋﾞ\" \"ビ\" #>   ..$ : chr [1:2] \"ﾌﾞ\" \"ブ\" #>   ..$ : chr [1:2] \"ﾍﾞ\" \"ベ\" #>   ..$ : chr [1:2] \"ﾎﾞ\" \"ボ\" #>   ..$ : chr [1:2] \"ﾊﾟ\" \"パ\" #>   ..$ : chr [1:2] \"ﾋﾟ\" \"ピ\" #>   ..$ : chr [1:2] \"ﾌﾟ\" \"プ\" #>   ..$ : chr [1:2] \"ﾍﾟ\" \"ペ\" #>   ..$ : chr [1:2] \"ﾎﾟ\" \"ポ\" #>   ..$ : chr [1:2] \"うﾞ\" \"ヴ\" #>   ..$ : chr [1:2] \"かﾞ\" \"が\" #>   ..$ : chr [1:2] \"きﾞ\" \"ぎ\" #>   ..$ : chr [1:2] \"くﾞ\" \"ぐ\" #>   ..$ : chr [1:2] \"けﾞ\" \"げ\" #>   ..$ : chr [1:2] \"こﾞ\" \"ご\" #>   ..$ : chr [1:2] \"さﾞ\" \"ざ\" #>   ..$ : chr [1:2] \"しﾞ\" \"じ\" #>   ..$ : chr [1:2] \"すﾞ\" \"ず\" #>   ..$ : chr [1:2] \"せﾞ\" \"ぜ\" #>   ..$ : chr [1:2] \"そﾞ\" \"ぞ\" #>   ..$ : chr [1:2] \"たﾞ\" \"だ\" #>   ..$ : chr [1:2] \"ちﾞ\" \"ぢ\" #>   ..$ : chr [1:2] \"つﾞ\" \"づ\" #>   ..$ : chr [1:2] \"てﾞ\" \"で\" #>   ..$ : chr [1:2] \"とﾞ\" \"ど\" #>   ..$ : chr [1:2] \"はﾞ\" \"ば\" #>   ..$ : chr [1:2] \"ひﾞ\" \"び\" #>   ..$ : chr [1:2] \"ふﾞ\" \"ぶ\" #>   ..$ : chr [1:2] \"へﾞ\" \"べ\" #>   ..$ : chr [1:2] \"ほﾞ\" \"ぼ\" #>   ..$ : chr [1:2] \"はﾟ\" \"ぱ\" #>   ..$ : chr [1:2] \"ひﾟ\" \"ぴ\" #>   ..$ : chr [1:2] \"ふﾟ\" \"ぷ\" #>   ..$ : chr [1:2] \"へﾟ\" \"ぺ\" #>   ..$ : chr [1:2] \"ほﾟ\" \"ぽ\" #>   ..$ : chr [1:2] \"ウﾞ\" \"ヴ\" #>   ..$ : chr [1:2] \"カﾞ\" \"ガ\" #>   ..$ : chr [1:2] \"キﾞ\" \"ギ\" #>   ..$ : chr [1:2] \"クﾞ\" \"グ\" #>   ..$ : chr [1:2] \"ケﾞ\" \"ゲ\" #>   ..$ : chr [1:2] \"コﾞ\" \"ゴ\" #>   ..$ : chr [1:2] \"サﾞ\" \"ザ\" #>   ..$ : chr [1:2] \"シﾞ\" \"ジ\" #>   ..$ : chr [1:2] \"スﾞ\" \"ズ\" #>   ..$ : chr [1:2] \"セﾞ\" \"ゼ\" #>   ..$ : chr [1:2] \"ソﾞ\" \"ゾ\" #>   ..$ : chr [1:2] \"タﾞ\" \"ダ\" #>   ..$ : chr [1:2] \"チﾞ\" \"ヂ\" #>   ..$ : chr [1:2] \"ツﾞ\" \"ヅ\" #>   ..$ : chr [1:2] \"テﾞ\" \"デ\" #>   ..$ : chr [1:2] \"トﾞ\" \"ド\" #>   ..$ : chr [1:2] \"ハﾞ\" \"バ\" #>   ..$ : chr [1:2] \"ヒﾞ\" \"ビ\" #>   ..$ : chr [1:2] \"フﾞ\" \"ブ\" #>   ..$ : chr [1:2] \"ヘﾞ\" \"ベ\" #>   ..$ : chr [1:2] \"ホﾞ\" \"ボ\" #>   ..$ : chr [1:2] \"ハﾟ\" \"パ\" #>   ..$ : chr [1:2] \"ヒﾟ\" \"ピ\" #>   ..$ : chr [1:2] \"フﾟ\" \"プ\" #>   ..$ : chr [1:2] \"ヘﾟ\" \"ペ\" #>   ..$ : chr [1:2] \"ホﾟ\" \"ポ\" #>   ..$ : chr [1:2] \"う゛\" \"ヴ\" #>   ..$ : chr [1:2] \"か゛\" \"が\" #>   ..$ : chr [1:2] \"き゛\" \"ぎ\" #>   ..$ : chr [1:2] \"く゛\" \"ぐ\" #>   ..$ : chr [1:2] \"け゛\" \"げ\" #>   ..$ : chr [1:2] \"こ゛\" \"ご\" #>   ..$ : chr [1:2] \"さ゛\" \"ざ\" #>   ..$ : chr [1:2] \"し゛\" \"じ\" #>   ..$ : chr [1:2] \"す゛\" \"ず\" #>   ..$ : chr [1:2] \"せ゛\" \"ぜ\" #>   ..$ : chr [1:2] \"そ゛\" \"ぞ\" #>   ..$ : chr [1:2] \"た゛\" \"だ\" #>   ..$ : chr [1:2] \"ち゛\" \"ぢ\" #>   ..$ : chr [1:2] \"つ゛\" \"づ\" #>   ..$ : chr [1:2] \"て゛\" \"で\" #>   ..$ : chr [1:2] \"と゛\" \"ど\" #>   ..$ : chr [1:2] \"は゛\" \"ば\" #>   ..$ : chr [1:2] \"ひ゛\" \"び\" #>   ..$ : chr [1:2] \"ふ゛\" \"ぶ\" #>   ..$ : chr [1:2] \"へ゛\" \"べ\" #>   ..$ : chr [1:2] \"ほ゛\" \"ぼ\" #>   .. [list output truncated]"},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill Japanese iteration marks — strj_fill_iter_mark","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"Fill Japanese iteration marks (Odoriji) previous characters.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"","code":"strj_fill_iter_mark(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"","code":"strj_fill_iter_mark(c(   \"\\u3042\\u3044\\u3046\\u309d\\u3003\\u304b\\u304d\",   \"\\u91d1\\u5b50\\u307f\\u3059\\u309e\",   \"\\u306e\\u305f\\u308a\\u3033\\u3035\\u304b\\u306a\",   \"\\u3057\\u308d\\uff0f\\u2033\\uff3c\\u3068\\u3057\\u305f\" )) #> [1] \"あいううゝかき\"  \"金子みすすﾞ\"     \"のたりたりかな\"  \"しろしﾞろとした\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":null,"dir":"Reference","previous_headings":"","what":"Hiraganize Japanese characters — strj_hiraganize","title":"Hiraganize Japanese characters — strj_hiraganize","text":"Hiraganize Japanese characters","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hiraganize Japanese characters — strj_hiraganize","text":"","code":"strj_hiraganize(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hiraganize Japanese characters — strj_hiraganize","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hiraganize Japanese characters — strj_hiraganize","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hiraganize Japanese characters — strj_hiraganize","text":"","code":"strj_hiraganize(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ) ) #> [1] \"あのいーはとーヴぉのすきとおった風\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":null,"dir":"Reference","previous_headings":"","what":"Katakanize Japanese characters — strj_katakanize","title":"Katakanize Japanese characters — strj_katakanize","text":"Katakanize Japanese characters","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Katakanize Japanese characters — strj_katakanize","text":"","code":"strj_katakanize(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Katakanize Japanese characters — strj_katakanize","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Katakanize Japanese characters — strj_katakanize","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Katakanize Japanese characters — strj_katakanize","text":"","code":"strj_katakanize(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ) ) #> [1] \"アノイーハトーヴォノスキトオッタ風\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert text following the rules of 'NEologd' — strj_normalize","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"Convert characters normalized style basing rules recommended Neologism dictionary MeCab.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"","code":"strj_normalize(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"Character vector.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"","code":"strj_normalize(   paste0(     \"\\u2015\\u2015\\u5357\\u30a2\\u30eb\\u30d7\\u30b9\",     \"\\u306e\\u3000\\u5929\\u7136\\u6c34-\\u3000\\uff33\",     \"\\uff50\\uff41\\uff52\\uff4b\\uff49\\uff4e\\uff47*\",     \"\\u3000\\uff2c\\uff45\\uff4d\\uff4f\\uff4e+\",     \"\\u3000\\u30ec\\u30e2\\u30f3\\u4e00\\u7d5e\\u308a\"   ) ) #> [1] \"ー南アルプスの天然水-Sparking* Lemon+レモン一絞り\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":null,"dir":"Reference","previous_headings":"","what":"Rewrite text using rewrite.def — strj_rewrite_as_def","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"Rewrite text using rewrite.def","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"","code":"strj_rewrite_as_def(text, as = read_rewrite_def())"},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"text Character vector. List.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"Character vector","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"","code":"strj_rewrite_as_def(   paste0(     \"\\u2015\\u2015\\u5357\\u30a2\\u30eb\",     \"\\u30d7\\u30b9\\u306e\\u3000\\u5929\",     \"\\u7136\\u6c34-\\u3000\\uff33\\uff50\",     \"\\uff41\\uff52\\uff4b\\uff49\\uff4e\\uff47*\",     \"\\u3000\\uff2c\\uff45\\uff4d\\uff4f\\uff4e+\",     \"\\u3000\\u30ec\\u30e2\\u30f3\\u4e00\\u7d5e\\u308a\"   ) ) #> [1] \"――南アルプスの 天然水- Sparking* Lemon+ レモン一絞り\" strj_rewrite_as_def(   \"\\u60e1\\u3068\\u5047\\u9762\\u306e\\u30eb\\u30fc\\u30eb\",   read_rewrite_def(system.file(\"def/kyuji.def\", package = \"audubon\")) ) #> [1] \"悪と仮面のルール\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":null,"dir":"Reference","previous_headings":"","what":"Romanize Japanese Hiragana and Katakana — strj_romanize","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"Romanize Japanese Hiragana Katakana","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"","code":"strj_romanize(   text,   config = c(\"wikipedia\", \"traditional hepburn\", \"modified hepburn\", \"kunrei\", \"nihon\") )"},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"text Character vector. config Configuration used romanize.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"","code":"strj_romanize(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ) ) #> [1] \"ano<U+012B>hat<U+014D>vonosukit<U+014D>tta\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Segment text into phrases — strj_segment","title":"Segment text into phrases — strj_segment","text":"Segment Japanese text several phrases using 'google/budoux' JavaScript module.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segment text into phrases — strj_segment","text":"","code":"strj_segment(text, format = c(\"list\", \"data.frame\"), split = FALSE)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Segment text into phrases — strj_segment","text":"text Character vector tokenized. format Output format. Choose list data.frame. split Logical. true, function splits vectors sentences using stringi::stri_split_boundaries(type = \"sentence\") tokenizing.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segment text into phrases — strj_segment","text":"List data.frame.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segment text into phrases — strj_segment","text":"","code":"strj_segment(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ) ) #> $`1` #> [1] \"あのイーハトーヴォの\" \"すきと\"               \"おった\"               #> [4] \"風\"                   #>  strj_segment(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ),   format = \"data.frame\" ) #>   doc_id                token #> 1      1 あのイーハトーヴォの #> 2      1               すきと #> 3      1               おった #> 4      1                   風"},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":null,"dir":"Reference","previous_headings":"","what":"Simply tokenize sentence — strj_tokenize","title":"Simply tokenize sentence — strj_tokenize","text":"Split given sentence tokens using stringi::stri_split_boundaries(type = \"word\").","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simply tokenize sentence — strj_tokenize","text":"","code":"strj_tokenize(text, format = c(\"list\", \"data.frame\"), split = FALSE)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simply tokenize sentence — strj_tokenize","text":"text Character vector tokenized. format Output format. Choose list data.frame. split Logical. true, function splits vectors sentences using stringi::stri_split_boundaries(type = \"sentence\") tokenizing.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simply tokenize sentence — strj_tokenize","text":"List data.frame.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simply tokenize sentence — strj_tokenize","text":"","code":"strj_tokenize(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ) ) #> $`1` #> [1] \"あの\"           \"イーハトーヴォ\" \"の\"             \"すき\"           #> [5] \"と\"             \"おっ\"           \"た\"             \"風\"             #>  strj_tokenize(   paste0(     \"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\",     \"\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\",     \"\\u3068\\u304a\\u3063\\u305f\\u98a8\"   ),   format = \"data.frame\" ) #>   doc_id          token #> 1      1           あの #> 2      1 イーハトーヴォ #> 3      1             の #> 4      1           すき #> 5      1             と #> 6      1           おっ #> 7      1             た #> 8      1             風"},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Transcribe Arabic to Kansuji — strj_transcribe_num","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"Transcribe Arabic integers Kansuji.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"","code":"strj_transcribe_num(int)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"int Integers.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"","code":"strj_transcribe_num(c(10L, 31415L)) #> [1] \"十\"             \"三万千四百十五\""},{"path":"https://paithiov909.github.io/audubon/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way. enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions). simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[. Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround. Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually : Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"}]
