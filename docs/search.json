[{"path":"https://paithiov909.github.io/audubon/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Akiru Kato. Maintainer.","code":""},{"path":"https://paithiov909.github.io/audubon/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kato (2022). audubon: R Package Various Japanese Text Processing. R package version 0.0.4.","code":"@Manual{,   title = {audubon: R Package for Various Japanese Text Processing},   author = {Akiru Kato},   year = {2022},   note = {R package version 0.0.4}, }"},{"path":"https://paithiov909.github.io/audubon/index.html","id":"audubon-","dir":"","previous_headings":"","what":"R Package for Various Japanese Text Processing","title":"R Package for Various Japanese Text Processing","text":"audubon R package various Japanese text processing contains: wrapper functions hakatashi/japanese.js R port SudachiCharNormalizer miscellaneous functions","code":""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R Package for Various Japanese Text Processing","text":"","code":"remotes::install_github(\"paithio909/audubon\")"},{"path":[]},{"path":"https://paithiov909.github.io/audubon/index.html","id":"fill-japanese-iteration-marks-踊り字","dir":"","previous_headings":"Usage","what":"Fill Japanese iteration marks (踊り字)","title":"R Package for Various Japanese Text Processing","text":"","code":"## 5文字以上あるとき直前の文字を繰り返して踊り字を置換する strj_fill_iter_mark(c(\"あいうゝ〃かき\",                       \"金子みすゞ\", ## 濁点付きの場合には半角の濁点を付ける                       \"のたり〳〵かな\", ## 2倍の踊り字（くの字点）まで対応している                       \"しろ／″＼とした\")) ## 青空文庫の記法も #> [1] \"あいううゝかき\"             \"金子みすすﾞ\"                #> [3] \"のたり<U+3033><U+3035>かな\" \"しろしﾞろとした\" ## 文字正規化とあわせて使う想定 strj_fill_iter_mark(\"いすゞエルフトラック\") %>%   strj_normalize() #> [1] \"いすずエルフトラック\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"character-class-conversion","dir":"","previous_headings":"Usage","what":"Character class conversion","title":"R Package for Various Japanese Text Processing","text":"","code":"strj_hiraganize(\"あのイーハトーヴォのすきとおった風\") #> [1] \"あのいーはとーヴぉのすきとおった風\" strj_katakanize(\"あのイーハトーヴォのすきとおった風\") #> [1] \"アノイーハトーヴォノスキトオッタ風\" strj_romanize(\"あのイーハトーヴォのすきとおった風\") #> [1] \"ano<U+012B>hat<U+014D>vonosukit<U+014D>tta\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"japanese-text-normalization-1","dir":"","previous_headings":"Usage","what":"Japanese text normalization (1)","title":"R Package for Various Japanese Text Processing","text":"","code":"## Neologd（https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja）の文字正規化 strj_normalize(\"――南アルプスの　天然水-　Ｓｐａｒｋｉｎｇ*　Ｌｅｍｏｎ+　レモン一絞り\") #> [1] \"ー南アルプスの天然水-Sparking* Lemon+レモン一絞り\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"japanese-text-normalization-2","dir":"","previous_headings":"Usage","what":"Japanese text normalization (2)","title":"R Package for Various Japanese Text Processing","text":"","code":"## ふつうのNFKC正規化 stringi::stri_trans_nfkc(\"Ⅹⅳ\") #> [1] \"Xiv\" ## Sudachiの文字正規化（rewrite.defによる文字置換＋NFKC正規化の部分）を移植したもの ## Sudachiのrewrite.defではローマ数字などはNFKC正規化されない strj_rewrite_as_def(\"Ⅹⅳ\") #> [1] \"Ⅹⅳ\" ## tolowerはしない strj_rewrite_as_def(\"謎のヒロインX\") #> [1] \"謎のヒロインX\" ## 旧字を新字体に寄せる strj_rewrite_as_def(\"惡と假面のルール\", read_rewrite_def(system.file(\"def/kyuji.def\", package = \"audubon\"))) #> [1] \"悪と仮面のルール\""},{"path":"https://paithiov909.github.io/audubon/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"R Package for Various Japanese Text Processing","text":"MIT license. Icons made iconixar www.flaticon.com.","code":""},{"path":"https://paithiov909.github.io/audubon/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 audubon authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_as_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Pack prettified output as quanteda tokens — gbs_as_tokens","title":"Pack prettified output as quanteda tokens — gbs_as_tokens","text":"Pack prettified output quanteda tokens","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_as_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pack prettified output as quanteda tokens — gbs_as_tokens","text":"","code":"gbs_as_tokens(df, pull = \"token\", n = 1L, sep = \"-\", what = \"fastestword\", ...)"},{"path":"https://paithiov909.github.io/audubon/reference/gbs_as_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pack prettified output as quanteda tokens — gbs_as_tokens","text":"df prettified data.frame tokens. pull Column packed text ngrams body. Default value token. n Integer internally passed ngrams tokenizer function created audubon::ngram_tokenizer() sep Character scalar internally used concatenator ngrams. Character scalar; tokenizer use quanteda::tokens(). ... arguments passed quanteda::tokens().","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_as_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pack prettified output as quanteda tokens — gbs_as_tokens","text":"quanteda 'token' class object.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/gbs_c.html","id":null,"dir":"Reference","previous_headings":"","what":"An alternative of RMeCabC — gbs_c","title":"An alternative of RMeCabC — gbs_c","text":"alternative RMeCabC","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An alternative of RMeCabC — gbs_c","text":"","code":"gbs_c(df, pull = c(\"token\", \"Original\"), names = \"POS1\")"},{"path":"https://paithiov909.github.io/audubon/reference/gbs_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An alternative of RMeCabC — gbs_c","text":"df prettified data.frame tokenized sentences. pull column name df. names column name df.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An alternative of RMeCabC — gbs_c","text":"list named vectors.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/gbs_dfm.html","id":null,"dir":"Reference","previous_headings":"","what":"An alternative of docDF family — gbs_dfm","title":"An alternative of docDF family — gbs_dfm","text":"Create sparse document-feature matrix. function shorthand audubon::gbs_as_tokens() quatenda::dfm().","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_dfm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An alternative of docDF family — gbs_dfm","text":"","code":"gbs_dfm(df, pull = \"token\", n = 1L, sep = \"-\", what = \"fastestword\", ...)"},{"path":"https://paithiov909.github.io/audubon/reference/gbs_dfm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An alternative of docDF family — gbs_dfm","text":"df prettified data.frame tokens. pull Column packed text ngrams body. Default value token. n Integer internally passed ngrams tokenizer function created audubon::ngram_tokenizer() sep Character scalar internally used concatenator ngrams. Character scalar; tokenizer use quanteda::tokens(). ... arguments passed quanteda::tokens().","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_dfm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An alternative of docDF family — gbs_dfm","text":"quanteda 'dfm' object.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/gbs_freq.html","id":null,"dir":"Reference","previous_headings":"","what":"An alternative of RMeCabFreq — gbs_freq","title":"An alternative of RMeCabFreq — gbs_freq","text":"alternative RMeCabFreq","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_freq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An alternative of RMeCabFreq — gbs_freq","text":"","code":"gbs_freq(df, ..., .name_repair = TRUE)"},{"path":"https://paithiov909.github.io/audubon/reference/gbs_freq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An alternative of RMeCabFreq — gbs_freq","text":"df prettified data.frame tokenized sentences. ... arguments passed dplyr::tally(). .name_repair Logical: true, rename column names RMeCabFreq-compatible style.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/gbs_freq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An alternative of RMeCabFreq — gbs_freq","text":"data.frame.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/gibasa.html","id":null,"dir":"Reference","previous_headings":"","what":"Gibasa functions family — gbs","title":"Gibasa functions family — gbs","text":"functions compact RMeCab alternatives based quanteda.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Ngrams tokenizer — ngram_tokenizer","title":"Ngrams tokenizer — ngram_tokenizer","text":"Make ngram tokenizer function.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ngrams tokenizer — ngram_tokenizer","text":"","code":"ngram_tokenizer(n = 1L, skip_word_none = FALSE, locale = NULL)"},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ngrams tokenizer — ngram_tokenizer","text":"n Integer. skip_word_none Logical. locale Character scalar. Pass NULL empty string default locale.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/ngram_tokenizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ngrams tokenizer — ngram_tokenizer","text":"ngram tokenizer function","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":null,"dir":"Reference","previous_headings":"","what":"Pack prettified data.frame of tokens — pack","title":"Pack prettified data.frame of tokens — pack","text":"Pack prettified data.frame tokens new data.frame corpus, compatible Text Interchange Formats.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pack prettified data.frame of tokens — pack","text":"","code":"pack(df, n = 1L, pull = \"token\", sep = \"-\", .collapse = \" \")"},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pack prettified data.frame of tokens — pack","text":"df prettified data.frame tokens. n Integer internally passed ngrams tokenizer function created audubon::ngram_tokenizer() pull Column packed text ngrams body. Default value token. sep Character scalar internally used concatenator ngrams. .collapse argument passed stringi::stri_join().","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pack prettified data.frame of tokens — pack","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"text-interchange-formats-tif-","dir":"Reference","previous_headings":"","what":"Text Interchange Formats (TIF)","title":"Pack prettified data.frame of tokens — pack","text":"Text Interchange Formats (TIF) set standards allows R text analysis packages target defined inputs outputs corpora, tokens, document-term matrices.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pack.html","id":"valid-data-frame-of-tokens","dir":"Reference","previous_headings":"","what":"Valid data.frame of tokens","title":"Pack prettified data.frame of tokens — pack","text":"prettified data.frame tokens data.frame object compatible TIF. TIF valid data.frame tokens expected one unique key column (named doc_id) text several feature columns tokens. feature columns must contain least token .","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":null,"dir":"Reference","previous_headings":"","what":"Read rewrite.def file — read_rewrite_def","title":"Read rewrite.def file — read_rewrite_def","text":"Read rewrite.def file","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read rewrite.def file — read_rewrite_def","text":"","code":"read_rewrite_def(   def_path = system.file(\"def/rewrite.def\", package = \"audubon\") )"},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read rewrite.def file — read_rewrite_def","text":"def_path Character scalar; path rewriting definition file.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/read_rewrite_def.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read rewrite.def file — read_rewrite_def","text":"List.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill Japanese iteration marks — strj_fill_iter_mark","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"Fill Japanese iteration marks (Odoriji) previous characters.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"","code":"strj_fill_iter_mark(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_fill_iter_mark.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill Japanese iteration marks — strj_fill_iter_mark","text":"","code":"strj_fill_iter_mark(c(\"\\u3042\\u3044\\u3046\\u309d\\u3003\\u304b\\u304d\",                       \"\\u91d1\\u5b50\\u307f\\u3059\\u309e\",                       \"\\u306e\\u305f\\u308a\\u3033\\u3035\\u304b\\u306a\",                       \"\\u3057\\u308d\\uff0f\\u2033\\uff3c\\u3068\\u3057\\u305f\")) #> [1] \"あいううゝかき\"  \"金子みすすﾞ\"     \"のたりたりかな\"  \"しろしﾞろとした\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":null,"dir":"Reference","previous_headings":"","what":"Hiraganize Japanese characters — strj_hiraganize","title":"Hiraganize Japanese characters — strj_hiraganize","text":"Hiraganize Japanese characters","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hiraganize Japanese characters — strj_hiraganize","text":"","code":"strj_hiraganize(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hiraganize Japanese characters — strj_hiraganize","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hiraganize Japanese characters — strj_hiraganize","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_hiraganize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hiraganize Japanese characters — strj_hiraganize","text":"","code":"strj_hiraganize(\"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\\u3068\\u304a\\u3063\\u305f\\u98a8\") #> [1] \"あのいーはとーヴぉのすきとおった風\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":null,"dir":"Reference","previous_headings":"","what":"Katakanize Japanese characters — strj_katakanize","title":"Katakanize Japanese characters — strj_katakanize","text":"Katakanize Japanese characters","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Katakanize Japanese characters — strj_katakanize","text":"","code":"strj_katakanize(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Katakanize Japanese characters — strj_katakanize","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Katakanize Japanese characters — strj_katakanize","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_katakanize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Katakanize Japanese characters — strj_katakanize","text":"","code":"strj_katakanize(\"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\\u3068\\u304a\\u3063\\u305f\\u98a8\") #> [1] \"アノイーハトーヴォノスキトオッタ風\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert text following the rules of 'NEologd' — strj_normalize","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"Convert characters normalized style basing rules recommended Neologism dictionary MeCab.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"","code":"strj_normalize(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"Character vector.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/audubon/reference/strj_normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert text following the rules of 'NEologd' — strj_normalize","text":"","code":"strj_normalize(\"\\u2015\\u2015\\u5357\\u30a2\\u30eb\\u30d7\\u30b9\\u306e\\u3000\\u5929\\u7136\\u6c34-\\u3000\\uff33\\uff50\\uff41\\uff52\\uff4b\\uff49\\uff4e\\uff47*\\u3000\\uff2c\\uff45\\uff4d\\uff4f\\uff4e+\\u3000\\u30ec\\u30e2\\u30f3\\u4e00\\u7d5e\\u308a\") #> [1] \"ー南アルプスの天然水-Sparking* Lemon+レモン一絞り\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":null,"dir":"Reference","previous_headings":"","what":"Rewrite text using rewrite.def — strj_rewrite_as_def","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"Rewrite text using rewrite.def","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"","code":"strj_rewrite_as_def(text, as = read_rewrite_def())"},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"text Character vector. List.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"Character vector","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_rewrite_as_def.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rewrite text using rewrite.def — strj_rewrite_as_def","text":"","code":"strj_rewrite_as_def(\"\\u2015\\u2015\\u5357\\u30a2\\u30eb\\u30d7\\u30b9\\u306e\\u3000\\u5929\\u7136\\u6c34-\\u3000\\uff33\\uff50\\uff41\\uff52\\uff4b\\uff49\\uff4e\\uff47*\\u3000\\uff2c\\uff45\\uff4d\\uff4f\\uff4e+\\u3000\\u30ec\\u30e2\\u30f3\\u4e00\\u7d5e\\u308a\") #> [1] \"――南アルプスの 天然水- Sparking* Lemon+ レモン一絞り\" strj_rewrite_as_def(\"\\u60e1\\u3068\\u5047\\u9762\\u306e\\u30eb\\u30fc\\u30eb\", read_rewrite_def(system.file(\"def/kyuji.def\", package = \"audubon\"))) #> [1] \"悪と仮面のルール\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":null,"dir":"Reference","previous_headings":"","what":"Romanize Japanese Hiragana and Katakana — strj_romanize","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"Romanize Japanese Hiragana Katakana","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"","code":"strj_romanize(   text,   config = c(\"wikipedia\", \"traditional hepburn\", \"modified hepburn\", \"kunrei\", \"nihon\") )"},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"text Character vector. config Config used romanize.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_romanize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Romanize Japanese Hiragana and Katakana — strj_romanize","text":"","code":"strj_romanize(\"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\\u3068\\u304a\\u3063\\u305f\\u98a8\") #> [1] \"ano<U+012B>hat<U+014D>vonosukit<U+014D>tta\""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Segment text into phrases — strj_segment","title":"Segment text into phrases — strj_segment","text":"Segment Japanese text several phrases using 'google/budoux' JavaScript module.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segment text into phrases — strj_segment","text":"","code":"strj_segment(text)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Segment text into phrases — strj_segment","text":"text Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segment text into phrases — strj_segment","text":"List.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segment text into phrases — strj_segment","text":"","code":"strj_segment(\"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\\u3068\\u304a\\u3063\\u305f\\u98a8\") #> [[1]] #> [1] \"あのイーハトーヴォの\" \"すきと\"               \"おった\"               #> [4] \"風\"                   #>"},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":null,"dir":"Reference","previous_headings":"","what":"Simply tokenize sentence — strj_tokenize","title":"Simply tokenize sentence — strj_tokenize","text":"Split given sentence tokens using stringi::stri_split_boundaries(type = \"word\").","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simply tokenize sentence — strj_tokenize","text":"","code":"strj_tokenize(sentence)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simply tokenize sentence — strj_tokenize","text":"sentence Character vector tokenized.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simply tokenize sentence — strj_tokenize","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_tokenize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simply tokenize sentence — strj_tokenize","text":"","code":"strj_tokenize(\"\\u3042\\u306e\\u30a4\\u30fc\\u30cf\\u30c8\\u30fc\\u30f4\\u30a9\\u306e\\u3059\\u304d\\u3068\\u304a\\u3063\\u305f\\u98a8\") #>   doc_id          token #> 1      1           あの #> 2      1 イーハトーヴォ #> 3      1             の #> 4      1           すき #> 5      1             と #> 6      1           おっ #> 7      1             た #> 8      1             風"},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Transcribe Arabic to Kansuji — strj_transcribe_num","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"Transcribe Arabic integers Kansuji.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"","code":"strj_transcribe_num(int)"},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"int Integers.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"Character vector.","code":""},{"path":"https://paithiov909.github.io/audubon/reference/strj_transcribe_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transcribe Arabic to Kansuji — strj_transcribe_num","text":"","code":"strj_transcribe_num(c(10L, 31415L)) #> [1] \"十\"             \"三万千四百十五\""},{"path":"https://paithiov909.github.io/audubon/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way. enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions). simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[. Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround. Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually : Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"}]
